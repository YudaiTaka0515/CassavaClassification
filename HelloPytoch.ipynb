{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"/Users/takahashiyuudai/Documents/Data/cassava-leaf-disease-classification\"\n",
    "CSV_PATH = 'train.csv'\n",
    "TRAIN_DIR = 'train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21392</th>\n",
       "      <td>999068805.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21393</th>\n",
       "      <td>999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21394</th>\n",
       "      <td>999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21395</th>\n",
       "      <td>999616605.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21396</th>\n",
       "      <td>999998473.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21397 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label\n",
       "0      1000015157.jpg      0\n",
       "1      1000201771.jpg      3\n",
       "2       100042118.jpg      1\n",
       "3      1000723321.jpg      1\n",
       "4      1000812911.jpg      3\n",
       "...               ...    ...\n",
       "21392   999068805.jpg      3\n",
       "21393   999329392.jpg      3\n",
       "21394   999474432.jpg      1\n",
       "21395   999616605.jpg      4\n",
       "21396   999998473.jpg      4\n",
       "\n",
       "[21397 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, CSV_PATH))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb0e80c7f28>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='label', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "train_images = []\n",
    "for image_path in df['image_id']:\n",
    "    train_dir = os.path.join(DATA_DIR, TRAIN_DIR)\n",
    "    image = cv2.imread(os.path.join(train_dir, image_path))\n",
    "#     print(image.shape)\n",
    "    train_images.append(image)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畳み込み層\n",
    "# conv2d(入力チャネル, 出力チャネル, カーネルサイズ)\n",
    "# 全結合層\n",
    "# Linear(入力サイズ, 出力サイズ)\n",
    "n_flatten = 16*147*197\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 8, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(8, 16, 5)\n",
    "        self.fc1 = torch.nn.Linear(n_flatten, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 5)\n",
    "        \n",
    "        self.max_pool = torch.nn.MaxPool2d(2, 2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = F.relu(x)\n",
    "        # ベクトルに変換するおまじない\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        \n",
    "        print(x.shape)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 600, 800])\n",
      "torch.Size([1, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0055, 0.0217, 0.2617, 0.7066, 0.0044]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "reshaped_image = np.expand_dims(train_images[0].transpose(2, 0, 1), 0).astype(np.float32)\n",
    "x = torch.from_numpy(reshaped_image)\n",
    "# print(x.shape)\n",
    "net = CNN()\n",
    "net = net.to(device)\n",
    "net(x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss関数， オプティマイザの設定\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer =  optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "# net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSetの実装\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.images = ''\n",
    "        self.labels = ''\n",
    "        pass\n",
    "    def __getitem(self, index):\n",
    "        return self.images[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
